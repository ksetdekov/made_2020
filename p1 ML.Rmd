---
title: "classification"
author: "Kirill Setdekov"
date: "09 08 2020"
output:
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	cache = TRUE
)
```

## import
```{r}
library(readr)
train <- read_csv("data/train.csv", col_names = FALSE)
# View(train)
test <- read_csv("data/test.csv", col_names = FALSE)
Y  <- read_csv("data/train-target.csv", 
    col_names = FALSE, col_types = cols(X1 = col_factor()))
names(Y) <- "Y"
train <- cbind(train,Y)
```


## prep
```{r}
library(ISLR)
library(ggplot2)
library(caret)

inTrain <- createDataPartition(train$Y, p=0.7, list = FALSE)
training <- train[inTrain,]
testing <- train[-inTrain,]
```
# exploratory
```{r}
library(dplyr)
violin_pair <- function(column) {
  print(ggplot(testing, aes(x=Y, y=testing[,column]))+   geom_violin() + ylab(column))
}

for (i in names(testing)[1:30]){
  violin_pair(i)
}


library(ggplot2)
library(GGally)
ggpairs(training[,c(1:10,31)])


library("Hmisc")
res2 <- rcorr(as.matrix(testing))

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}
View(flattenCorrMatrix(res2$r, res2$P))
library(corrplot)
res <- cor(as.matrix(cbind(testing[,1:30],as.numeric(testing[,31]))))

corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
corrplot(res2$r, type="upper", order="hclust", 
         p.mat = res2$P, sig.level = 0.01, insig = "blank")
```


# ensemble
```{r}
library(party)
require(randomForest)
mod1 <- train(Y ~., method ="glm", data = training[,-c(1, 6, 8, 10, 18, 20, 22)])
mod2 <- train(Y~., method ="rf", data = training[,-c(1, 6, 8, 10, 18, 20, 22)], trControl = trainControl(method = "cv"),number = 10)
mod3 <- train(Y~., method ="rpart", data = training[,-c(1, 6, 8, 10, 18, 20, 22)])
mod4 <- train(Y~., method ="ctree", data = training[,-c(1, 6, 8, 10, 18, 20, 22)])
# mod4 <- train(Y~., method ="ctree", data = training[,-10])

mod5 <- train(Y~.,method = "ada", data = training[,-c(1, 6, 8, 10, 18, 20, 22)])
```

### compare them
```{r dependson=c(-1)}
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
pred3 <- predict(mod3, testing)
pred4 <- predict(mod4, testing)
MLmetrics::Accuracy(pred4,testing$Y)

confusionMatrix(pred1,testing$Y)
confusionMatrix(pred2,testing$Y)

confusionMatrix(pred3,testing$Y)

confusionMatrix(pred4,testing$Y)

library(rattle)
fancyRpartPlot(mod3$finalModel)
plot(mod4$finalModel)
plot(mod1$finalModel)
```


```{r}
predDF4 <- data.frame(pred1, pred2, pred3, pred4, Y = testing$Y)
combModFit4 <- train(Y~., method = "gam", data = predDF4)
combPred4 <- predict(combModFit4,predDF4)
```

```{r}
MLmetrics::Accuracy(y_pred = pred1,y_true = testing$Y)
MLmetrics::Accuracy(y_pred = pred2,y_true = testing$Y)
MLmetrics::Accuracy(y_pred = pred3,y_true = testing$Y)
MLmetrics::Accuracy(y_pred = pred4,y_true = testing$Y)
MLmetrics::Accuracy(y_pred = combPred4,y_true = testing$Y)
plot(combModFit4)
```

```{r}
pred1V <- predict(mod1, test)
pred2V <- predict(mod2, test)
pred3V <- predict(mod3, test)
pred4V <- predict(mod4, test)
predVDF4 <-
    data.frame(
        pred1 = pred1V,
        pred2 = pred2V,
        pred3 = pred3V,
        pred4 = pred4V
    )
combPredV5 <- predict(combModFit4,predVDF4,type="prob")
# View(combPredV5)
rfresults <- predict(mod2, test,type="prob")
ctreeresults <- predict(mod4, test,type="prob")
glm_results <- predict(mod1, test,type="prob" )

View(glm_results)

```

## export
```{r}
export <- combPredV5[,1]
write.table(export, file = "results.csv",row.names = FALSE, dec = ".", sep = ",", col.names = F)
```

